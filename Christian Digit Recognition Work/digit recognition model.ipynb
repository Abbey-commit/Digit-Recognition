{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below is the loading of MNIST datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'DESCR', 'details', 'categories', 'url'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The above output shows that our dataset has dictionary structure. So we proceed and check for the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = mnist[\"data\"],mnist[\"target\"]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's take a peek at one item set digit to 4 in the dataset and check what its output could look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "some_digit = X[4]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "plt.imshow(some_digit_image, cmap = mpl.cm.binary, interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This look like 9. To be sure let's check the label of that item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From the what the output looks like above, it showed that our label are in string data type. We will convert them to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=y.astype(np.uint8)\n",
    "y[4] # you can uncomment the line below and view the entire labels\n",
    "# y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Done. So we go ahead and create a train and test split. Note: Mnist had already create a train and test set in ratio of 60000:10000 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's create a binary classifier that can distinguish between two digit, if our input \"is 9 or not 9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_9 = (y_train == 9) # True for all 5s, False for all other digits.\n",
    "y_test_9 = (y_test == 9)\n",
    "y_test_9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we use a stochastic gradient classifier to use and train a classifier choosen to be SGDClassifier, and fit the classifier with our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### having done that, let's cross check to see if our model really can predict exact digit we want it to. We expect a boolean result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.predict([some_digit])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we go ahead and do a cross validation to check the performance measurement of the model we just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9456\n",
      "0.95195\n",
      "0.9509\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "skfolds = StratifiedKFold(n_splits=3, random_state=42)\n",
    "for train_index, test_index in skfolds.split(X_train, y_train_9):\n",
    "    clone_clf = clone(sgd_clf)\n",
    "    X_train_folds = X_train[train_index]\n",
    "    y_train_folds = y_train_9[train_index]\n",
    "    X_test_fold = X_train[test_index]\n",
    "    y_test_fold = y_train_9[test_index]\n",
    "    clone_clf.fit(X_train_folds, y_train_folds)\n",
    "    y_pred = clone_clf.predict(X_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    print(n_correct / len(y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From the above code in chosen in place of cross_val_score and used clone with it, we used a stratifiedkfold for our cross validation and clone library to train our fold and test the fold that print 0.9502, 0.96565 and 0.96495"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we decide to use the cross_val_score() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9456 , 0.95195, 0.9509 ])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf, X_train, y_train_9, cv=3, scoring=\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class Never9Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8993 , 0.8999 , 0.90335])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "never_9_clf = Never9Classifier()\n",
    "cross_val_score(never_9_clf, X_train, y_train_9, cv=3, scoring=\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now in a bid to use a better performance metrix we want to use confusion metrix. And the prediction function is chosen contrary to score in the previous cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### So in preparation for the confusion matrix we use cross val prediction because we need to predict first and compare our prediction with the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_9, cv=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[52715,  1336],\n",
       "       [ 1695,  4254]], dtype=int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train_9, y_train_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The above output shows the predict value and actual value in columns and rows respectively. The first row (number of non nine digit row) shows true negative and false negative predictions respetively, while the second row (yes nine digit predictions) showed false positive and true positive respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's call out our precision to show how percentage measure of time it has to detect nine digit in the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7610017889087657"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision_score(y_train_9, y_train_pred) # 52715 / (52715 + 1336)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let call out recall to show percentage number of entire nine digit it correctly detect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7150781643973777"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train_9, y_train_pred) # == 4254 / (4254 + 1695)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for f1-score. Our model test of performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.737325591472398"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_train_9, y_train_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's check for cases where the model can compare between two or more classes. Multiclass classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sklearn by default detect other digit using binary classification for multiclass classification except for SVM where it is required to use One versus all. Note: ono stands for one versus one and ova stands for one versus all in the below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9], dtype=uint8)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.fit(X_train, y_train) # y_train, not y_train_5\n",
    "sgd_clf.predict([some_digit])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-45606.88156161, -20077.79903687, -23620.86693862,\n",
       "        -11077.35532351,  -8578.08720996,  -7133.8897717 ,\n",
       "        -27033.93740198,  -8312.88994614,  -3257.29010483,\n",
       "          2193.22821614]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_digit_scores = sgd_clf.decision_function([some_digit])\n",
    "some_digit_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(some_digit_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.classes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.classes_[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One versus one is used as classifier used to create multi class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9], dtype=uint8)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " from sklearn.multiclass import OneVsOneClassifier\n",
    "ovo_clf = OneVsOneClassifier(SGDClassifier(random_state=42))\n",
    "ovo_clf.fit(X_train, y_train)\n",
    "ovo_clf.predict([some_digit])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ovo_clf.estimators_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_9, cv=3,\n",
    " method=\"predict_proba\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9], dtype=uint8)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_clf.fit(X_train, y_train)\n",
    "forest_clf.predict([some_digit])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.01, 0.  , 0.  , 0.01, 0.01, 0.  , 0.  , 0.02, 0.95]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_clf.predict_proba([some_digit])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's evaluate our multiclass classier using cross validation score and see the result we get doing that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87365, 0.85835, 0.8689 ])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### let's use scaling with standard scaler to push for a better result if possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    "cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
